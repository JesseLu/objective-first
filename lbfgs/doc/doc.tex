\documentclass{article}
\usepackage{amsmath,amssymb}
\begin{document}
As taken from section 19.3 of \cite{NW04}, 
    the interior point method obtains step direction $p$ by solving
\begin{equation}
\begin{bmatrix}
    \nabla^2_{xx}\mathcal{L} & 0 & A_E^T(x) & A_I^T(x) \\
    0 & \Sigma & 0 & -I \\
    A_E(x) & 0 & 0 & 0 \\
    A_I(x) & -I & 0 & 0
\end{bmatrix}
\begin{bmatrix} p_x \\ p_s \\ -p_y \\ -p_z \end{bmatrix}
    = -
\begin{bmatrix}
    \nabla f(x) - A_E^T(x) y - A_I^T(x) z \\
    z - \mu S^{-1} e \\
    c_E(x) \\
    c_I(x) - s
\end{bmatrix}.
\end{equation}

This equation can be simplified by removing $p_s$ and then $p_z$.
The reduced system is then
\begin{equation}
\begin{bmatrix}
    \nabla^2_{xx}\mathcal{L} + A_I^T(x) \Sigma A_I^T(x) & A_E^T(x) \\
    A_E(x) & 0 
\end{bmatrix}
\begin{bmatrix} p_x \\ -p_y \end{bmatrix}
    = -
\begin{bmatrix}
    \nabla f(x) - A_E^T(x) y - A_I(x) (z - \Sigma c_I(x) + \mu S^{-1} e) \\
    c_E(x)
\end{bmatrix},
\end{equation}
where
\begin{align}
    p_s &= A_I(x) p_x + c_I(x) - s \\
    p_z &= -\Sigma A_I(x) p_x - \Sigma c_I(x) + \mu S^{-1} e.
\end{align}

We can focus the problem by only considering 
    simple bound inequality constraints $l \le x \le u$, and
    affine equality constraints $A x - b = 0$.
Then our problem is written down as
\begin{multline}
\begin{bmatrix}
    \nabla^2 f(x) + \Sigma_0 + \Sigma_1 & A^T \\
    A & 0 
\end{bmatrix}
\begin{bmatrix} p_x \\ -p_y \end{bmatrix}
    = \\ -
\begin{bmatrix}
    \nabla f(x) - A^T y + (-z_0 + \Sigma_0 (x - l) - \mu S_0^{-1} e) 
                        + (z_1 - \Sigma_1 (u - x) + \mu S_1^{-1} e) \\
    A x - b
\end{bmatrix},
\end{multline}
where
\begin{align}
    p_{s_0} &= p_x + (x - l) - s_0 \\
    p_{z_0} &= -\Sigma_0 p_x - \Sigma_0 (x - l) + \mu S_0^{-1} e \\
    p_{s_1} &= -p_x + (u - x) - s_1 \\
    p_{z_1} &= \Sigma_1 p_x - \Sigma_1 (u - x) + \mu S_1^{-1} e,
\end{align}
and the error function used is
\begin{multline}
E(x, s_0, s_1, y, z_0, z_1, \mu) = \text{max}\{ 
    \| \nabla f(x) - A^T y - z_0 + z_1 \|, \\
    \| S_0 z_0 - \mu e \|, 
    \| S_1 z_1 - \mu e \|, 
    \| A x - b \|, 
    \|(x - l) - s_0 \|, 
    \|(u - x) - s_1 \| \}
\end{multline}

Lastly, inspired from section 11.7.3 of \cite{BL04}, 
    we perform a backtracking line search (see section 9.2 or \cite{BL04})
    in order to guarantee decrease of the residual
    $r(x^+, s_0^+, s_1^+, y^+, z_0^+, z_1^+, \mu)$ where,
    \begin{align*}
    x^+ &= x + t \alpha_p p_x \\
    s_0^+ &= s_0+t \alpha_p p_{s_0} \\
    s_1^+ &= s_1+t \alpha_p p_{s_1} \\
    y^+ &= y +\alpha_d p_y \\
    z_0^+ &= z_0 + \alpha_d p_{z_0} \\
    z_1^+ &= z_1+\alpha_d p_{z_1} 
    \end{align*}
    and,
\begin{multline}
    r(x, s_0, s_1, y, z_0, z_1, \mu) = \\
\left\|
\begin{bmatrix}
    \nabla f(x) - A^T y + (-z_0 + \Sigma_0 (x - l) - \mu S_0^{-1} e) 
                        + (z_1 - \Sigma_1 (u - x) + \mu S_1^{-1} e) \\
    A x - b
\end{bmatrix}\right\|_2.
\end{multline}
The exit condition for the line search is 
    \begin{equation} r(x^+, s_0^+, s_1^+, y^+, z_0^+, z_1^+, \mu) \le
    (1-\alpha t) r(x, s_0, s_1, y, z_0, z_1, \mu).
    \end{equation}
where $t$ is initially set to $t = \alpha_p$.






\begin{thebibliography}{99}
\bibitem{NW04} Nocedal and Wright, 
    Numerical Optimization, Second Edition (Cambridge 2004)
\bibitem{BL04} Boyd and Vandenberghe,
    Convex Optimization (Cambridge 2004)
\end{thebibliography}
\end{document}
