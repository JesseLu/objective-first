
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Figure 7.1: Logistic regression</title><meta name="generator" content="MATLAB 7.9"><meta name="date" content="2009-11-12"><meta name="m-file" content="logistics_"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Figure 7.1: Logistic regression</h1><pre class="codeinput"><span class="comment">% Section 7.1.1</span>
<span class="comment">% Boyd &amp; Vandenberghe, "Convex Optimization"</span>
<span class="comment">% Original by Lieven Vandenberghe</span>
<span class="comment">% Adapted for CVX by Argyris Zymnis - 01/31/06</span>
<span class="comment">%</span>
<span class="comment">% We consider a binary random variable y with prob(y=1) = p and</span>
<span class="comment">% prob(y=0) = 1-p. We assume that that y depends on a vector of</span>
<span class="comment">% explanatory variables u in R^n. The logistic model has the form</span>
<span class="comment">% p = exp(a'*u+b)/(1+exp(a'*u+b)), where a and b are the model parameters.</span>
<span class="comment">% We have m data points (u_1,y_1),...,(u_m,y_m).</span>
<span class="comment">% We can reorder the data so that for u_1,..,u_q the outcome is y = 1</span>
<span class="comment">% and for u_(q+1),...,u_m the outcome is y = 0. Then it can be shown</span>
<span class="comment">% that the ML estimate of a and b can be found by solving</span>
<span class="comment">%</span>
<span class="comment">% minimize sum_{i=1,..,q}(a'*u_i+b) - sum_i(log(1+exp(a'*u_i+b)))</span>
<span class="comment">%</span>
<span class="comment">% In this case we have m = 100 and the u_i are just scalars.</span>
<span class="comment">% The figure shows the data as well as the function</span>
<span class="comment">% f(x) = exp(aml*x+bml)/(1+exp(aml*x+bml)) where aml and bml are the</span>
<span class="comment">% ML estimates of a and b.</span>

randn(<span class="string">'state'</span>,0);
rand(<span class="string">'state'</span>,0);

<span class="comment">% Generate data</span>
a =  1;
b = -5 ;
m= 100;

u = 10*rand(m,1);
y = (rand(m,1) &lt; exp(a*u+b)./(1+exp(a*u+b)));
plot(u,y,<span class="string">'o'</span>)
axis([-1,11,-0.1, 1.1]);

<span class="comment">% Solve problem</span>
<span class="comment">%</span>
<span class="comment">% minimize  -(sum_(y_i=1) ui)*a - b + sum log (1+exp(a*ui+b)</span>

U = [ones(m,1) u];
cvx_expert <span class="string">true</span>
cvx_begin
    variables <span class="string">x(2)</span>
    maximize(y'*U*x-sum(log_sum_exp([zeros(1,m); x'*U'])))
cvx_end

<span class="comment">% Plot results and logistic function</span>

ind1 = find(y==1);
ind2 = find(y==0);

aml = x(2);  bml = x(1);
us = linspace(-1,11,1000)';
ps = exp(aml*us + bml)./(1+exp(aml*us+bml));

dots = plot(us,ps,<span class="string">'-'</span>, u(ind1),y(ind1),<span class="string">'o'</span>,<span class="keyword">...</span>
     u(ind2),y(ind2),<span class="string">'o'</span>);

axis([-1, 11,-0.1,1.1]);
xlabel(<span class="string">'x'</span>);
ylabel(<span class="string">'y'</span>);
</pre><pre class="codeoutput"> 
Successive approximation method to be employed.
   For improved efficiency, sedumi is solving the dual problem.
   sedumi will be called several times to refine the solution.
   Original size: 600 variables, 202 equality constraints
   200 exponentials add 1600 variables, 1000 equality constraints
-----------------------------------------------------------------
          Errors   
Act Centering    Conic    Status
-----------------------------------
200 4.877e+00  2.483e+00  Solved
187 1.917e-01  3.038e-03  Inaccurate/Solved
200 1.308e-01  1.425e-03  Solved
187 3.250e-03  1.932e-05  Inaccurate/Solved
174 1.627e-04  3.268e-05S Inaccurate/Solved
187 3.632e-04S 1.562e-05  Inaccurate/Solved
187 8.138e-06  1.552e-05S Inaccurate/Solved
200 4.678e-03S 5.693e-06  Inaccurate/Solved
200 1.121e-04  3.265e-06  Inaccurate/Solved
200 8.993e-06  3.347e-06S Inaccurate/Solved
200 1.401e-06  3.244e-06S Inaccurate/Solved
-----------------------------------------------------------------
Status: Failed
Optimal value (cvx_optval): NaN
</pre><img vspace="5" hspace="5" src="logistics__01.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.9<br></p></div><!--
##### SOURCE BEGIN #####
%% Figure 7.1: Logistic regression

% Section 7.1.1
% Boyd & Vandenberghe, "Convex Optimization"
% Original by Lieven Vandenberghe
% Adapted for CVX by Argyris Zymnis - 01/31/06
%
% We consider a binary random variable y with prob(y=1) = p and
% prob(y=0) = 1-p. We assume that that y depends on a vector of
% explanatory variables u in R^n. The logistic model has the form
% p = exp(a'*u+b)/(1+exp(a'*u+b)), where a and b are the model parameters.
% We have m data points (u_1,y_1),...,(u_m,y_m).
% We can reorder the data so that for u_1,..,u_q the outcome is y = 1
% and for u_(q+1),...,u_m the outcome is y = 0. Then it can be shown
% that the ML estimate of a and b can be found by solving
%
% minimize sum_{i=1,..,q}(a'*u_i+b) - sum_i(log(1+exp(a'*u_i+b)))
%
% In this case we have m = 100 and the u_i are just scalars.
% The figure shows the data as well as the function
% f(x) = exp(aml*x+bml)/(1+exp(aml*x+bml)) where aml and bml are the
% ML estimates of a and b.

randn('state',0);
rand('state',0);

% Generate data
a =  1;
b = -5 ;
m= 100;

u = 10*rand(m,1);
y = (rand(m,1) < exp(a*u+b)./(1+exp(a*u+b)));
plot(u,y,'o')
axis([-1,11,-0.1, 1.1]);

% Solve problem
%
% minimize  -(sum_(y_i=1) ui)*a - b + sum log (1+exp(a*ui+b)

U = [ones(m,1) u];
cvx_expert true
cvx_begin
    variables x(2)
    maximize(y'*U*x-sum(log_sum_exp([zeros(1,m); x'*U'])))
cvx_end

% Plot results and logistic function

ind1 = find(y==1);
ind2 = find(y==0);

aml = x(2);  bml = x(1);
us = linspace(-1,11,1000)';
ps = exp(aml*us + bml)./(1+exp(aml*us+bml));

dots = plot(us,ps,'-', u(ind1),y(ind1),'o',...
     u(ind2),y(ind2),'o');

axis([-1, 11,-0.1,1.1]);
xlabel('x');
ylabel('y');

##### SOURCE END #####
--></body></html>