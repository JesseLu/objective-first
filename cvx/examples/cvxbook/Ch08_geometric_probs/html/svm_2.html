
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Figure 8.11: Approximate linear discrimination via support vector classifier</title><meta name="generator" content="MATLAB 7.9"><meta name="date" content="2009-11-12"><meta name="m-file" content="svm_2_"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Figure 8.11: Approximate linear discrimination via support vector classifier</h1><pre class="codeinput"><span class="comment">% Section 8.6.1, Boyd &amp; Vandenberghe "Convex Optimization"</span>
<span class="comment">% Original by Lieven Vandenberghe</span>
<span class="comment">% Adapted for CVX by Joelle Skaf - 10/16/05</span>
<span class="comment">% (a figure is generated)</span>
<span class="comment">%</span>
<span class="comment">% The goal is to find a function f(x) = a'*x - b that classifies the non-</span>
<span class="comment">% separable points {x_1,...,x_N} and {y_1,...,y_M} by doing a trade-off</span>
<span class="comment">% between the number of misclassifications and the width of the separating</span>
<span class="comment">% slab. a and b can be obtained by solving the following problem:</span>
<span class="comment">%           minimize    ||a||_2 + gamma*(1'*u + 1'*v)</span>
<span class="comment">%               s.t.    a'*x_i - b &gt;= 1 - u_i        for i = 1,...,N</span>
<span class="comment">%                       a'*y_i - b &lt;= -(1 - v_i)     for i = 1,...,M</span>
<span class="comment">%                       u &gt;= 0 and v &gt;= 0</span>
<span class="comment">% where gamma gives the relative weight of the number of misclassified</span>
<span class="comment">% points compared to the width of the slab.</span>

<span class="comment">% data generation</span>
n = 2;
randn(<span class="string">'state'</span>,2);
N = 50; M = 50;
Y = [1.5+0.9*randn(1,0.6*N), 1.5+0.7*randn(1,0.4*N);
     2*(randn(1,0.6*N)+1), 2*(randn(1,0.4*N)-1)];
X = [-1.5+0.9*randn(1,0.6*M),  -1.5+0.7*randn(1,0.4*M);
      2*(randn(1,0.6*M)-1), 2*(randn(1,0.4*M)+1)];
T = [-1 1; 1 1];
Y = T*Y;  X = T*X;
g = 0.1;            <span class="comment">% gamma</span>

<span class="comment">% Solution via CVX</span>
cvx_begin
    variables <span class="string">a(n)</span> <span class="string">b(1)</span> <span class="string">u(N)</span> <span class="string">v(M)</span>
    minimize (norm(a) + g*(ones(1,N)*u + ones(1,M)*v))
    X'*a - b &gt;= 1 - u;
    Y'*a - b &lt;= -(1 - v);
    u &gt;= 0;
    v &gt;= 0;
cvx_end

<span class="comment">% Displaying results</span>
linewidth = 0.5;  <span class="comment">% for the squares and circles</span>
t_min = min([X(1,:),Y(1,:)]);
t_max = max([X(1,:),Y(1,:)]);
tt = linspace(t_min-1,t_max+1,100);
p = -a(1)*tt/a(2) + b/a(2);
p1 = -a(1)*tt/a(2) + (b+1)/a(2);
p2 = -a(1)*tt/a(2) + (b-1)/a(2);

graph = plot(X(1,:),X(2,:), <span class="string">'o'</span>, Y(1,:), Y(2,:), <span class="string">'o'</span>);
set(graph(1),<span class="string">'LineWidth'</span>,linewidth);
set(graph(2),<span class="string">'LineWidth'</span>,linewidth);
set(graph(2),<span class="string">'MarkerFaceColor'</span>,[0 0.5 0]);
hold <span class="string">on</span>;
plot(tt,p, <span class="string">'-r'</span>, tt,p1, <span class="string">'--r'</span>, tt,p2, <span class="string">'--r'</span>);
axis <span class="string">equal</span>
title(<span class="string">'Approximate linear discrimination via support vector classifier'</span>);
<span class="comment">% print -deps svc-discr2.eps</span>
</pre><pre class="codeoutput"> 
Calling sedumi: 203 variables, 104 equality constraints
   For improved efficiency, sedumi is solving the dual problem.
------------------------------------------------------------
SeDuMi 1.21 by AdvOL, 2005-2008 and Jos F. Sturm, 1998-2003.
Alg = 2: xz-corrector, Adaptive Step-Differentiation, theta = 0.250, beta = 0.500
eqs m = 104, order n = 203, dim = 204, blocks = 2
nnz(A) = 503 + 0, nnz(ADA) = 714, nnz(L) = 409
 it :     b*y       gap    delta  rate   t/tP*  t/tD*   feas cg cg  prec
  0 :            1.77E+02 0.000
  1 :  -5.39E+00 8.55E+01 0.000 0.4840 0.9000 0.9000   2.18  1  1  9.8E+01
  2 :  -4.32E+00 5.38E+01 0.000 0.6290 0.9000 0.9000   2.94  1  1  3.7E+01
  3 :  -2.99E+00 1.64E+01 0.000 0.3059 0.9000 0.9000   2.18  1  1  7.4E+00
  4 :  -2.47E+00 7.28E+00 0.000 0.4428 0.9000 0.9000   0.99  1  1  3.5E+00
  5 :  -2.21E+00 3.58E+00 0.000 0.4912 0.9000 0.9000   0.78  1  1  1.9E+00
  6 :  -2.05E+00 1.94E+00 0.000 0.5414 0.9000 0.9000   0.76  1  1  1.1E+00
  7 :  -1.94E+00 9.49E-01 0.000 0.4899 0.9000 0.9000   0.85  1  1  5.7E-01
  8 :  -1.88E+00 4.15E-01 0.000 0.4380 0.9000 0.9000   0.91  1  1  2.6E-01
  9 :  -1.85E+00 1.78E-01 0.000 0.4277 0.9000 0.9000   0.97  1  1  1.1E-01
 10 :  -1.84E+00 2.38E-02 0.000 0.1339 0.9280 0.9000   0.94  1  1  2.3E-02
 11 :  -1.83E+00 1.04E-03 0.000 0.0439 0.9900 0.9326   1.00  1  1  1.3E-03
 12 :  -1.83E+00 1.83E-04 0.000 0.1757 0.9122 0.9000   1.00  1  1  1.4E-04
 13 :  -1.83E+00 3.98E-05 0.000 0.2170 0.9114 0.9000   1.00  1  1  2.2E-05
 14 :  -1.83E+00 5.92E-06 0.000 0.1486 0.9000 0.9097   1.00  1  1  4.1E-06
 15 :  -1.83E+00 1.65E-07 0.061 0.0279 0.9903 0.9900   1.00  1  1  8.1E-08
 16 :  -1.83E+00 1.25E-08 0.000 0.0755 0.9900 0.9900   1.00  1  1  6.2E-09

iter seconds digits       c*x               b*y
 16      0.1   8.2 -1.8257002098e+00 -1.8257002220e+00
|Ax-b| =   4.3e-09, [Ay-c]_+ =   3.6E-10, |x|=  1.7e+00, |y|=  3.5e+00

Detailed timing (sec)
   Pre          IPM          Post
1.000E-02    7.000E-02    0.000E+00    
Max-norms: ||b||=1, ||c|| = 1,
Cholesky |add|=0, |skip| = 0, ||L.L|| = 5.71996.
------------------------------------------------------------
Status: Solved
Optimal value (cvx_optval): +1.8257
</pre><img vspace="5" hspace="5" src="svm_2__01.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.9<br></p></div><!--
##### SOURCE BEGIN #####
%% Figure 8.11: Approximate linear discrimination via support vector classifier

% Section 8.6.1, Boyd & Vandenberghe "Convex Optimization"
% Original by Lieven Vandenberghe
% Adapted for CVX by Joelle Skaf - 10/16/05
% (a figure is generated)
%
% The goal is to find a function f(x) = a'*x - b that classifies the non-
% separable points {x_1,...,x_N} and {y_1,...,y_M} by doing a trade-off
% between the number of misclassifications and the width of the separating
% slab. a and b can be obtained by solving the following problem:
%           minimize    ||a||_2 + gamma*(1'*u + 1'*v)
%               s.t.    a'*x_i - b >= 1 - u_i        for i = 1,...,N
%                       a'*y_i - b <= -(1 - v_i)     for i = 1,...,M
%                       u >= 0 and v >= 0
% where gamma gives the relative weight of the number of misclassified
% points compared to the width of the slab.

% data generation
n = 2;
randn('state',2);
N = 50; M = 50;
Y = [1.5+0.9*randn(1,0.6*N), 1.5+0.7*randn(1,0.4*N);
     2*(randn(1,0.6*N)+1), 2*(randn(1,0.4*N)-1)];
X = [-1.5+0.9*randn(1,0.6*M),  -1.5+0.7*randn(1,0.4*M);
      2*(randn(1,0.6*M)-1), 2*(randn(1,0.4*M)+1)];
T = [-1 1; 1 1];
Y = T*Y;  X = T*X;
g = 0.1;            % gamma

% Solution via CVX
cvx_begin
    variables a(n) b(1) u(N) v(M)
    minimize (norm(a) + g*(ones(1,N)*u + ones(1,M)*v))
    X'*a - b >= 1 - u;
    Y'*a - b <= -(1 - v);
    u >= 0;
    v >= 0;
cvx_end

% Displaying results
linewidth = 0.5;  % for the squares and circles
t_min = min([X(1,:),Y(1,:)]);
t_max = max([X(1,:),Y(1,:)]);
tt = linspace(t_min-1,t_max+1,100);
p = -a(1)*tt/a(2) + b/a(2);
p1 = -a(1)*tt/a(2) + (b+1)/a(2);
p2 = -a(1)*tt/a(2) + (b-1)/a(2);

graph = plot(X(1,:),X(2,:), 'o', Y(1,:), Y(2,:), 'o');
set(graph(1),'LineWidth',linewidth);
set(graph(2),'LineWidth',linewidth);
set(graph(2),'MarkerFaceColor',[0 0.5 0]);
hold on;
plot(tt,p, '-r', tt,p1, 'REPLACE_WITH_DASH_DASHr', tt,p2, 'REPLACE_WITH_DASH_DASHr');
axis equal
title('Approximate linear discrimination via support vector classifier');
% print -deps svc-discr2.eps

##### SOURCE END #####
--></body></html>